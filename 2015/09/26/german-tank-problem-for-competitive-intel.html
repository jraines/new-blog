<!doctype html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv='X-UA-Compatible' content='IE=edge;chrome=1' />
    <link href="../../../stylesheets/syntax.css" rel="stylesheet" type="text/css" />
    <link href="../../../stylesheets/main.css" rel="stylesheet" type="text/css" />
    <meta property="og:image" content="" />
    <meta property="og:title" content="The German Tank Problem For Competitive Intel" />
    <meta property="og:url" content="http://jeremyraines.com/2015/09/26/german-tank-problem-for-competitive-intel.html" />
    <meta property="og:description" content="" />

    <script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

    <link href="//maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet">

    <title>Jeremy Raines - The German Tank Problem For Competitive Intel</title>

    <link rel="alternate" type="application/atom+xml" title="Atom Feed" href="/feed.xml" />
  </head>
  <body>
    <div id="main" role="main">
      <h1>The German Tank Problem</h1>

<h2>Or Why To Obfuscate Your User IDs</h2>

<p>(note, this is pulled largely from the Wikipedia page, where there is additional derivation
of these equations.  This post started as an exercise in understanding by explaining, and ended
as an exercise in learning LaTex and seeing how high I could raise my blood pressure)</p>

<p>In World War II, Allied intelligence used conventional intelligence and statistical
estimation to try to guess the production of German tanks.</p>

<p>The statistical estimates, which were based on a handful of serial numbers from
captured tanks, turned out to be much, much more accurate.</p>

<p>From a frequentist perspective, this estimation is given by the formula:</p>

<p>\[N = m + {m - k \over k}\]</p>

<p>where m is the max serial number from the sample, and k is the size of the sample.
Intuitively, this is sample maximum plus the average gap between observations in the sample</p>

<p>A Bayesian analysis yields a probability mass function.</p>

<p>\[P(N = n) =
\begin{cases}
  0 &amp; \quad \text{if } n &lt; m\cr
  {k -1 \over k} {{ m - 1 \choose k - 1 } \over { n \choose k }} &amp; \quad \text{otherwise}
\end{cases}\]</p>

<blockquote>
<p>A probability mass function differs from a probability density function (pdf) in that the latter is associated with continuous rather than discrete random variables; the values of the latter are not probabilities as such: a pdf must be integrated over an interval to yield a probability.  (source: Wikipedia)</p>
</blockquote>

<p>From this we can get the mean and standard deviation of the distribution in order to estimate.</p>

<p>\[N \approx \mu \pm \sigma \]</p>

<p>The mean of a probability distribution is:</p>

<p>\[\mu = \sum_{\substack{x}} xP(x)\]</p>

<p>(Note: in wikipedia, this is referred to as &ldquo;order of magnitude&rdquo; &ndash; why?)</p>

<p>So, in this case it is:</p>

<p>\[\mu = \sum_{\substack{n}} n \times (N = n \text{ | } M = m, K = k) \]</p>

<p>Alright, so what&rsquo;s the probability that N = n, given m and k?</p>

<p>Conditional probability tells us that:</p>

<p>\[(n | m,k) = (m | n,k){(n | k) \over (m | k)}\]</p>

<p>The first term on the right-hand side is the probability that the max serial number
is equal to m, when n is known</p>

<p>The numerator of the second term is the credibility that the total number of tanks
is equal to n when k tanks have been observed but before the serial numbers have
been observed. Assume that it has a discrete uniform distribution.</p>

<p>The denominator is  the probability that the maximum serial number is equal to m
once k tanks have been observed but before the serial numbers have actually been observed.
\scriptstyle (m\mid k) can be re-written in terms of the other quantities by marginalizing
over all possible \scriptstyle n.</p>

<p>For k &gt;= 4, there are formulas to get the mean and standard deviation (see wikipedia for derivation)</p>

    </div>
  </body>
</html>
